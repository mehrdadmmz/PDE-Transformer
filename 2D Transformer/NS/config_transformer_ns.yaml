defaults:
  - _self_
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

hydra:
  output_subdir: null
  run:
    dir: .

dataset: null

args: &args # generic
  model_name: "Transformer"
  if_training: True # set False for evaluation-only
  continue_training: False
  num_workers: 12
  batch_size: 8
  seed: 0

  # sequence / task
  initial_step: 10 # context length fed to ViT
  t_train: 1000 # NOT used in single-step mode
  training_type: "single" # change to "autoregressive" for autoregressive training

  # optimiser + schedule
  learning_rate: 1.e-3
  epochs: 20
  scheduler: cosine # {cosine, step}
  scheduler_step: 100
  scheduler_gamma: 0.5
  warmup_steps: 0

  # data
  base_path: "../data_gen/ns_256/"
  train_subsample: [0.5, 0.25, 24]

  # model hyperparams (transformer)
  img_size: 256
  patch_size: 16
  tubelet_size: 2
  in_chans: 3
  encoder_embed_dim: 768
  encoder_num_heads: 12
  decoder_embed_dim: 512
  decoder_num_heads: 8
  decoder_depth: 8
  drop_path_rate: 0.1 # stochastic depth
  ssl: false # set true for pixel-SSL head

  # logging / plotting
  plot: False
  channel_plot: 0
  x_min: -1
  x_max: 1
  y_min: -1
  y_max: 1
  t_min: 0
  t_max: 5

basic_ds2:
  <<: *args
  train_subsample: [0.5, 0.25, 24]

basic_ds4:
  <<: *args
  train_subsample: [1, 0.5, 24]

basic_ds8:
  <<: *args
  train_subsample: [2, 1, 24]

basic_ds16:
  <<: *args
  train_subsample: [4, 2, 48]

basic_ds32:
  <<: *args
  train_subsample: [8, 4, 96]

basic_ds48:
  <<: *args
  train_subsample: [12, 6, 144]

basic_ds64:
  <<: *args
  train_subsample: [16, 8, 192]
